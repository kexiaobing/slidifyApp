data(iris)
library(ggplot2)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Specis, p=0.7, list=FALSE)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain]
testing <- iris[-inTrain]
names(training)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
names(training)
names(testing)
dim(training)
dim(testing)
library(caret)
modFit <- train(Species~., method="rpart", data=training)
modFit$finalModel
training <- read.csv("pml-training.csv", header=TRUE)
testing <- read.csv("pml-testing.csv", header=TRUE)
nza_cols_train <- nearZeroVar(training)
library(caret)
library(rpart)
library(randomForest)
nza_cols_train <- nearZeroVar(training)
if (length(nza_cols_train)>0) training <- training[,-nza_cols_train]
nza_cols_test <- nearZeroVar(testing)
if (length(nza_cols_test)>0) testing <- testing[,-nza_cols_test]
allmisscols_train <- apply(training,2, function(x){sum(is.na(x))})
training_clean <- training[, which(allmisscols_train == 0)]
allmisscols_test <- apply(testing,2, function(x){sum(is.na(x))})
testing_clean <- testing[, which(allmisscols_test ==0)]
names(training_clean)
names(testing_clean)
training_clean <- training_clean[, -c(1,2,3,4,5,6)]
testing_clean <- testing_clean[, -c(1,2,3,4,5,6)]
set.seed(23232)
#cross validation to form real training dataset and testing dataset
inTrain <- createDataPartition(y=training_clean$classe, p=0.7, list=FALSE)
trainData <- training_clean[inTrain,]
testData <- training_clean[-inTrain,]
dim(trainData)
#Fit a model with 70% training data
modFit <- train(classe ~ ., method="rpart", data=trainData)
modFit
predictions <- predict(modFit, testData)
preditions
predictions
confusionMatrix(predictions, testData$classe)
modFit_rf <- train(classe ~ ., method="rf", data=trainData)   #performance very slow...
training <- read.csv("pml-training.csv", header=TRUE)
testing <- read.csv("pml-testing.csv", header=TRUE)
nza_cols_train <- nearZeroVar(training)
library(caret)
library(rpart)
library(randomForest)
nza_cols_train <- nearZeroVar(training)
df <- read.csv("pml-training.csv")
library(caret)
removecols <- nearZeroVar(df)
nearzerodf <- df[,-removecols]
names(nearzerodf)
View(nearzerodf)
cleandf <- subset(nearzerodf, select=-c(X,user_name,raw_timestamp_part_1,raw_timestamp_part_2,cvtd_timestamp,var_accel_forearm,amplitude_pitch_forearm,min_pitch_forearm,max_picth_forearm,var_yaw_dumbbell,stddev_yaw_dumbbell,avg_yaw_dumbbell,var_pitch_dumbbell,stddev_pitch_dumbbell,avg_pitch_dumbbell,var_roll_dumbbell,stddev_roll_dumbbell,avg_roll_dumbbell,var_accel_dumbbell,amplitude_pitch_dumbbell,amplitude_roll_dumbbell,min_pitch_dumbbell,min_roll_dumbbell,max_picth_dumbbell,max_roll_dumbbell,max_roll_belt,max_picth_belt,min_roll_belt,min_pitch_belt,amplitude_roll_belt,amplitude_pitch_belt,var_total_accel_belt, avg_roll_belt,stddev_roll_belt, var_roll_belt,avg_pitch_belt, stddev_pitch_belt,var_pitch_belt,avg_yaw_belt,stddev_yaw_belt,var_yaw_belt,var_accel_arm,max_picth_arm,max_yaw_arm,min_yaw_arm,amplitude_yaw_arm))
traindf <- cleandf
names(cleandf)
View(cleandf)
select <- createDataPartition(traindf$classe, p = 0.7, list = FALSE)
dataTrain <- traindf[select,]
dataCV <- traindf[-select,]
#4. Using the model training set above, train a model using RandomForest
model <- train(classe ~ ., data=dataTrain, method="rf", verbose=FALSE)
df <- read.csv("pml-training.csv")
library(caret)
removecols <- nearZeroVar(df)
nearzerodf <- df[,-removecols]
cleandf <- subset(nearzerodf, select=-c(X,user_name,raw_timestamp_part_1,raw_timestamp_part_2,cvtd_timestamp,var_accel_forearm,amplitude_pitch_forearm,min_pitch_forearm,max_picth_forearm,var_yaw_dumbbell,stddev_yaw_dumbbell,avg_yaw_dumbbell,var_pitch_dumbbell,stddev_pitch_dumbbell,avg_pitch_dumbbell,var_roll_dumbbell,stddev_roll_dumbbell,avg_roll_dumbbell,var_accel_dumbbell,amplitude_pitch_dumbbell,amplitude_roll_dumbbell,min_pitch_dumbbell,min_roll_dumbbell,max_picth_dumbbell,max_roll_dumbbell,max_roll_belt,max_picth_belt,min_roll_belt,min_pitch_belt,amplitude_roll_belt,amplitude_pitch_belt,var_total_accel_belt, avg_roll_belt,stddev_roll_belt, var_roll_belt,avg_pitch_belt, stddev_pitch_belt,var_pitch_belt,avg_yaw_belt,stddev_yaw_belt,var_yaw_belt,var_accel_arm,max_picth_arm,max_yaw_arm,min_yaw_arm,amplitude_yaw_arm))
traindf <- cleandf
select <- createDataPartition(traindf$classe, p = 0.7, list = FALSE)
dataTrain <- traindf[select,]
dataCV <- traindf[-select,]
model <- train(classe ~ ., data=dataTrain, method="rf", verbose=FALSE)
training <- read.csv("pml-training.csv", header=TRUE)
testing <- read.csv("pml-testing.csv", header=TRUE)
library(caret)
library(rpart)
library(randomForest)
nza_cols_train <- nearZeroVar(training)
if (length(nza_cols_train)>0) training <- training[,-nza_cols_train]
nza_cols_test <- nearZeroVar(testing)
if (length(nza_cols_test)>0) testing <- testing[,-nza_cols_test]
##remove the column(s) with all NA values
allmisscols_train <- apply(training,2, function(x){sum(is.na(x))})
training_clean <- training[, which(allmisscols_train == 0)]
allmisscols_test <- apply(testing,2, function(x){sum(is.na(x))})
testing_clean <- testing[, which(allmisscols_test ==0)]
training_clean <- training_clean[, -c(1,2,3,4,5,6)]
testing_clean <- testing_clean[, -c(1,2,3,4,5,6)]
set.seed(23)
inTrain <- createDataPartition(y=training_clean$classe, p=0.7, list=FALSE)
trainData <- training_clean[inTrain,]
testData <- training_clean[-inTrain,]
dim(trainData)
modFit_rpart <- train(classe ~ ., method="glm", data=trainData)
modFit_rpart <- train(classe ~ ., method="nb", data=trainData)
library(klaR)
modFit_nb <- train(classe ~ ., method="nb", data=trainData)
training <- read.csv("pml-training.csv", header=TRUE)
testing <- read.csv("pml-testing.csv", header=TRUE)
library(caret)
library(rpart)
library(randomForest)
nza_cols_train <- nearZeroVar(training)
if (length(nza_cols_train)>0) training <- training[,-nza_cols_train]
nza_cols_test <- nearZeroVar(testing)
if (length(nza_cols_test)>0) testing <- testing[,-nza_cols_test]
allmisscols_train <- apply(training,2, function(x){sum(is.na(x))})
training_clean <- training[, which(allmisscols_train == 0)]
allmisscols_test <- apply(testing,2, function(x){sum(is.na(x))})
testing_clean <- testing[, which(allmisscols_test ==0)]
training_clean <- training_clean[, -c(1,2,3,4,5,6)]
testing_clean <- testing_clean[, -c(1,2,3,4,5,6)]
set.seed(23)
inTrain <- createDataPartition(y=training_clean$classe, p=0.1, list=FALSE)
trainData <- training_clean[inTrain,]
testData <- training_clean[-inTrain,]
dim(trainData)
modFit_rf <- train(classe ~ ., method="rf", data=trainData)   #performance very slow, can't finish in 30 mins
modFit
modFit_rf
nonTrain <- training_clean[-inTrain,]
inCV <- createDataPartition(y=nonTrain$classe, p=0.01, list=FALSE)
cvData <- nonTrain[inCV,]
otherData <- nonTrain[-inCV,]
dim(cvData)
predictions <- predict(modFit_rf, cvData)
predictions
confusionMatrix(predictions, cvData$classe)
predict(modFit, newdata=testing_clean)
predict(modFit_rf, newdata=testing_clean)
training <- read.csv("pml-training.csv", header=TRUE)
testing <- read.csv("pml-testing.csv", header=TRUE)
library(caret)
library(rpart)
library(randomForest)
nza_cols_train <- nearZeroVar(training)
if (length(nza_cols_train)>0) training <- training[,-nza_cols_train]
nza_cols_test <- nearZeroVar(testing)
if (length(nza_cols_test)>0) testing <- testing[,-nza_cols_test]
allmisscols_train <- apply(training,2, function(x){sum(is.na(x))})
training_clean <- training[, which(allmisscols_train == 0)]
allmisscols_test <- apply(testing,2, function(x){sum(is.na(x))})
testing_clean <- testing[, which(allmisscols_test ==0)]
training_clean <- training_clean[, -c(1,2,3,4,5,6)]
testing_clean <- testing_clean[, -c(1,2,3,4,5,6)]
set.seed(23)
inTrain <- createDataPartition(y=training_clean$classe, p=0.2, list=FALSE)
trainData <- training_clean[inTrain,]
nonTrain <- training_clean[-inTrain,]
inCV <- createDataPartition(y=nonTrain$classe, p=0.01, list=FALSE)
cvData <- nonTrain[inCV,]
otherData <- nonTrain[-inCV,]
dim(cvData)
modFit_rf <- train(classe ~ ., method="rf", data=trainData)   #performance very slow, can't finish in 30 mins
modFit_rf
predictions <- predict(modFit_rf, cvData)
predictions
confusionMatrix(predictions, cvData$classe)
modFit_rf2 <- randomForest(classe ~ ., data=trainData)
modFit_rf2
predictions <- predict(modFit_rf2, cvData)
predictions
confusionMatrix(predictions, cvData$classe)
predict(modFit_rf2, newdata=testing_clean)
inTrain <- createDataPartition(y=training_clean$classe, p=0.7, list=FALSE)
trainData <- training_clean[inTrain,]
nonTrain <- training_clean[-inTrain,]
inCV <- createDataPartition(y=nonTrain$classe, p=0.1, list=FALSE)
cvData <- nonTrain[inCV,]
otherData <- nonTrain[-inCV,]
dim(cvData)
modFit_rf2 <- randomForest(classe ~ ., data=trainData)
predictions <- predict(modFit_rf2, cvData)
predictions
confusionMatrix(predictions, cvData$classe)
predict(modFit_rf2, newdata=testing_clean)
cvData <- training_clean[-inTrain,]
dim(cvData)
predictions <- predict(modFit_rf2, cvData)
predictions
confusionMatrix(predictions, cvData$classe)
modFit_rf2
confusionMatrix(predictions, cvData$classe)
library(caret)
library(randomForest)
str(training_clean)
modFit_rt2
training <- read.csv("pml-training.csv", header=TRUE)
testing <- read.csv("pml-testing.csv", header=TRUE)
#Explore the data
dim(training)
dim(testing)
#Load support package
library(caret)
library(randomForest)
#clean the data
#remove near zero variables,IDs, irrelevant data
nza_cols_train <- nearZeroVar(training)
if (length(nza_cols_train)>0) training <- training[,-nza_cols_train]
##remove the column(s) with all NA values
allmisscols_train <- apply(training,2, function(x){sum(is.na(x))})
training_clean <- training[, which(allmisscols_train == 0)]
dim(training_clean)
str(training_clean)
training_clean <- training_clean[, -c(1,2,3,4,5,6)]
set.seed(23)
#create real training dataset and cross validation dataset
inTrain <- createDataPartition(y=training_clean$classe, p=0.7, list=FALSE)
trainData <- training_clean[inTrain,]
cvData <- training_clean[-inTrain,]
dim(trainData)
modFit_rf <- randomForest(classe ~ ., data=trainData)
plot(modFit_rf)
predictions <- predict(modFit_rf, cvData)
# summarize results
confusionMatrix(predictions, cvData$classe)
modFit_rt
modFit_rf
modFit_rt$finalModel
modFit_rf$finalModel
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(voewl.train)
str(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
str(vowel.train)
str(vowel.test)
vowel.test$y <- as.factor(vowel.test$y)
str(vowel.test)
modTrain <- train(y~., method=randomForest, data=vowel.train)
library(caret)
modTrain <- train(y~., method=randomForest, data=vowel.train)
modTrain <- train(y~., method="rf", data=vowel.train)
modTrain-gmb <- train(y~., method="gmb", data=vowel.train)
modTrain-gbm <- train(y~., method="gbm", data=vowel.train)
modTrain
modTrain-gbm
modTrain-gbm <- train(y~., method="gbm", data=vowel.train, verbose=FALSE)
modTrainGbm = train(y~., method="gbm", data=vowel.train, verbose=FALSE)
modTrainGbm
modTrain$Accuracy
modTrain$finalModel
modTrainGbm$finalModel
accuracy(modTrain)
predTrain <- predict(modTrain, vowel.test)
confusionMatrix(predTrain, vowel.test$y)
predGBM <- predict(modTrainGbm, vowel.test)
confusionMatrix(predGBM, vowel.test$y)
set.seed(33833)
modTrain <- train(y~., method="rf", data=vowel.train)
predTrain <- predict(modTrain, vowel.test)
confusionMatrix(predTrain, vowel.test$y)
modTrainGbm = train(y~., method="gbm", data=vowel.train, verbose=FALSE)
predGBM <- predict(modTrainGbm, vowel.test)
confusionMatrix(predGBM, vowel.test$y)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
str(training)
modRF <- train(diagnosis.~, method="rf", data=training)
modRF <- train(diagnosis.~, method="rf", data=training)
modRF <- train(diagnosis~., method="rf", data=training)
predRF <- predict(modRF, testing)
confusionMatrix(predRF, testing$diagnosis)
modGBM <- train(diagnosis~., method="gbm", data=training)
modGBM <- train(diagnosis~., method="gbm", data=training, verbose=FALSE)
predGBM <- predict(modGBM, testing)
confusionMatrix(predGBM, testing$diagnosis)
modLDA <- train(diagnosis~., method="lda", data=training)
predLDA <- predict(modLDA, testing)
confusionMatrix(predLDA, testing$diagnosis)
predDF <- data.frame(predRF, predGBM, predLDA, diagnosis=testing$diagnosis)
modComb <- train(diagnosis~., method="rf", data=predDF)
predComb <- predict(modComb, predDF)
confusionMatrix(predComb, predDF$diagnosis)
predDF
str(predDF)
confusionMatrix(predComb, testing$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
str(training)
model <- train(CompressiveStrength~., method="lasso", data=training)
pred <- predict(model, testing)
confusionMatrix(pred, testing$CompressiveStrength)
set.seed(233)
model <- train(CompressiveStrength~., method="lasso", data=training)
pred <- predict(model, testing)
confusionMatrix(pred, testing$CompressiveStrength)
pred
model$finalModel
plot.enet
?plot.enet
model$finalModel
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
library(caret)
fit <- train(CompressiveStrength ~ ., data = training, method = "svmRadial")
prediction <- predict(fit, testing)
accuracy(prediction, testing$CompressiveStrength)
confusionMatrix(prediction, testing$CompressiveStrength)
libracy(forcast)
library(forcast)
library(forecast)
insall.packages("forecast")
install.packages("forecast")
library(forecast)
accuracy(prediction, testing$CompressiveStrength)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
model <- train(CompressiveStrength~., method="lasso", data=training)
pred <- predict(model, testing)
plot.enet(pred$finalModel, xvar = "penalty", use.color = TRUE)
plot.enet(model$finalModel, xvar = "penalty", use.color = TRUE)
library(forecast)
library(lubridate)  # For year() function below
install.packages("lubridate")
library(lubridate)  # For year() function below
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
str(training)
str(testing)
str(tstrain)
library(forecast)
library(lubridate)  # For year() function below
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
fit <- bats(tstrain)
fit
forecast(fit, testing)
forecast(fit)
fc <- forecast(fit)
fc
plot(fc)
accuracy(fc, testing)
accuracy(fc, testing$visitsTumblr)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
modRF <- train(diagnosis~., method="rf", data=training)
predRF <- predict(modRF, testing)
confusionMatrix(predRF, testing$diagnosis)
modGBM <- train(diagnosis~., method="gbm", data=training, verbose=FALSE)
predGBM <- predict(modGBM, testing)
confusionMatrix(predGBM, testing$diagnosis)
modLDA <- train(diagnosis~., method="lda", data=training)
predLDA <- predict(modLDA, testing)
confusionMatrix(predLDA, testing$diagnosis)
predDF <- data.frame(predRF, predGBM, predLDA, diagnosis=testing$diagnosis)
modComb <- train(diagnosis~., method="rf", data=predDF)
predComb <- predict(modComb, testing)
confusionMatrix(predComb, testing$diagnosis)
?forecast
dim(tstrain)
library(forecast)
library(lubridate)  # For year() function below
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
fit <- bats(tstrain)
dim(tstrain)
dim(tstrain)[1]
dim(testing)
dim(testing)[1]
fc <- forecast(fit, level=95, h=dim(testing)[1])
fc
fcast <- forecast(fit, level=95, h=dim(testing)[1])
names(fcast)
str(fcast)
install.packages("shiny")
library(shiny)
runExample("01-hello")
runExample("01_hello")
runExample("02_text")
runExample("03_reactivity")
install.packages("devtools")
require(devtools); install_github(’rCharts’, ’ramnathv’)
require(devtools)
install_github(’rCharts’, ’ramnathv’)
?install_github
install_github(’rCharts’, ’ramnathv’)
install_github(’rCharts’)
install_github('ramnathv/rCharts')
devtools::install_github("ropensci/plotly")
install_github(’ramnathv/slidify’)
install_github(’ramnathv\slidify’)
install_github(’slidify’, ’ramnathv’)
install_github('ramnathv/slidify')
install_github('ramnathv/slidifyLibraries')
library(rCharts)
data(airquality)
head(airquality)
dTable(airquality, sPaginationType = "full_numbers")
d <- data.frame(airquality, stringsAsFactors = FALSE) print(d)
data.frame(airquality, stringsAsFactors = FALSE)
installed_packages
"rtools" %in% install.package()
"rtools" %in% installed.package()
"rtools" %in% installed.packages()
install.packages("rtools")
"rChars" %in% installed.packages()
"rCharts" %in% installed.packages()
"methods" %in% installed.packages()
?setClass
require("rtools")
head(getS3method("mean", "default"), 10)
install.packages("DDPQuiz3")
library("DDPQuiz3")
?yhat
shiny::runApp('ShinyApp-1')
shiny::runApp('ShinyApp-2')
shiny::runApp('ShinyApp-2')
shiny::runApp('ShinyApp-2')
shiny::runApp('ShinyApp-2')
shiny::runApp('ShinyApp-2')
shiny::runApp('ShinyApp-2')
shiny::runApp('ShinyApp-2')
install.packages('devtools')
devtools::install_github('rstudio/shinyapps')
shinyapps::setAccountInfo(name='kexiaobing',
token='27F5EE9D26BEF5D694661ADF8962C950',
secret='<SECRET>')
shinyapps::setAccountInfo(name='kexiaobing', token='27F5EE9D26BEF5D694661ADF8962C950', secret='jkEp2vMJfIDjwSJdwMubS1KVkCwOlFhdobzUEo12')
library(shinyapps)
shinyapps::deployApp('ShinyApp-2')
shiny::runApp('ShinyApp-2')
shiny::runApp('ShinyApp-2')
shiny::runApp('ShinyApp-2')
shinyapps::deployApp('ShinyApp-2')
require("devtools")
require("slidify")
getwd()
setwd("~/GitHub/slidifyApp")
browseURL("index.html")
slidify("index.rmd")
browseURL("index.html")
shiny::runApp('~/ShinyApp-2')
slidify("index.rmd")
browseURL("index.html")
slidify("index.rmd")
browseURL("index.html")
slidify("index.rmd")
browseURL("index.html")
slidify("index.rmd")
browseURL("index.html")
slidify("index.rmd")
browseURL("index.html")
slidify("index.rmd")
browseURL("index.html")
slidify("index.rmd")
browseURL("index.html")
slidify("index.rmd")
browseURL("index.html")
slidify("index.rmd")
browseURL("index.html")
slidify("index.rmd")
browseURL("index.html")
slidify("index.rmd")
browseURL("index.html")
slidify("index.rmd")
browseURL("index.html")
slidify("index.rmd")
browseURL("index.html")
slidify("index.rmd")
browseURL("index.html")
browseURL("index.html")
slidify("index.rmd")
browseURL("index.html")
